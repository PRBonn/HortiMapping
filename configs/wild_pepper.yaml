run_name: wild_sweetpepper # for general data

# data path:
deepsdf_dir: './deepsdf/models/sweetpepper_32' 

data_dir: './data/BUP20_example_data'

cam_info_path: './data/BUP20_example_data/cam_info.yaml'
baseline_name: none 

# processing range
begin_submap: 1
begin_frame: 0
end_frame: 2000
every_frame: 1

device: cuda

opt: # joint pose and shape optimization for the crops
  scale_on: true     # estimate scale (sim3) or not (se3)
  lm:                # levenberg-marquardt optimization related
    lm_on: true      # levenberg-marquardt optimization instead of gauss-newton
    lm_eye: false    # use identity damping matrix or not
    lm_lambda_0: 0.1 # lm initial damping factor lambda
    s_damp: 1e-3      # additional damping for the scale estimation (1e-3)
  pose_init:         # pose initial guess
    rot_on: true     
    scale_on: true
  recon:
    n_pts: 2000      # the number of the point sampled from the object's mesh (before cleaning)
    cluster_dist_m: 0.01 # the distance for filtering isolated clusters (the noise) from the object
    robust_th_m: 0.01 # robust kernel threshold
  render:            # rendering loss related
    n_fg_pix: 200    # count of the sampled foreground pixels
    n_bg_pix: 200    # count of the sampled background pixels
    n_bg_pad: 20     # padding of the background bounding box from the foreground bounding box on each side
    n_frame: 10      # max count of the image frame used for calculating the rendering loss
    n_sample_on_ray: 30 # count of the sampled points on each rendering ray
    log_sdf_occ: true # use the logistic function for sdf to occ. prob. convertion (or just a linear convertion)
    occ_cutoff_m: 0.01  # cut-off threshold for converting between the sdf and occupancy probability 
    occlusion_on: true  # occlusion aware rendering loss (do not take the potential occludded area in to account)
    robust_th_m: 0.05 # robust kernel threshold
  weight:
    w_recon: 1    # weight for the deepsdf reconstruction loss
    w_depth: 5e-2 # 5e-2   # weight for the depth rendering loss
    w_mask: 5e-4 # 1e-4      # weight for the mask rendering loss
    w_codereg: 5e-4 # larger would cause the pose more stable, but smaller would lead to more variance on the shape (5e-4)
  converge:
    max_iter: 50    # max iteration number 
    epsilon_g: 1e-4 # convergence tolerance for gradient
    epsilon_c: 1e-2 # convergence tolerance for shape latent code' change rate
    epsilon_t: 1e-3 # convergence tolerance for pose parameters (translation, m)
    epsilon_r: 1e-0 # convergence tolerance for pose parameters (rotation, degree)
    epsilon_s: 1e-3 # convergence tolerance for pose parameters (scale, %)
  robust_iter: 5 # begin to use the robust loss from this iteration
  outlier:
    scale_max: 1.25
    scale_min: 0.5
    rot_max_deg: 60

vis:
  vis_on: true
  vis_pause_s: 0.05
  object_radius_max_m: 0.08
  mc_res_mm: 4.0
  render_view: false
  rot_img: false # for 720 * 1280 images (for BUP20, false, others, true)
  show_pix_sample: false
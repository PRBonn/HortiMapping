run_name: cka_sweetpepper # for the benchmark

use_homa: true
useable_only: false
render_on: false

baseline_name: none # select from CoRe, DeepSDF, CPD, PFSGD, SEFit

# data path:
deepsdf_dir: './deepsdf/models/sweetpepper_32' 

data_dir: ["your/path/", "your/path2/"]

fruit_id: none # if none, we will use the testset in split

# processing range
begin_submap: 0
begin_frame: 0
end_frame: 2000
every_frame: 1

# used for lab pepper experiment
frame_per_fruit: 20

device: cuda

opt: # joint pose and shape optimization for the crops
  scale_on: true     # estimate scale (sim3) or not (se3)
  lm:                # levenberg-marquardt optimization related
    lm_on: true      # levenberg-marquardt optimization instead of gauss-newton
    lm_eye: false    # use identity damping matrix or not
    lm_lambda_0: 0.5 # 0.1 # lm initial damping factor lambda
    s_damp: 1e-3     # additional damping for the scale estimation (1e-3) #1e-3
  pose_init:         # pose initial guess
    rot_on: true     
    scale_on: true
  recon:
    n_pts: 2000      # the number of the point sampled from the object's mesh (before cleaning) # 2000
    cluster_dist_m: 0.01 # the distance for filtering isolated clusters (the noise) from the object # 0.01
    robust_th_m: 0.01 # robust kernel threshold # 0.005
  render:            # rendering loss related
    n_fg_pix: 200    # count of the sampled foreground pixels
    n_bg_pix: 200    # count of the sampled background pixels
    n_bg_pad: 20     # padding of the background bounding box from the foreground bounding box on each side
    n_frame: 10      # max count of the image frame used for calculating the rendering loss
    n_sample_on_ray: 30 # count of the sampled points on each rendering ray
    log_sdf_occ: true # use the logistic function for sdf to occ. prob. convertion (or just a linear convertion)
    occ_cutoff_m: 0.01  # cut-off threshold for converting between the sdf and occupancy probability 
    occlusion_on: true  # occlusion aware rendering loss (do not take the potential occludded area in to account)
    robust_th_m: 0.05 # robust kernel threshold
  weight:
    w_recon: 1    # weight for the deepsdf reconstruction loss
    w_depth: 5e-2 # 2e-2 # 5e-2   # weight for the depth rendering loss
    w_mask: 1e-3 # 5e-4 # 1e-4      # weight for the mask rendering loss
    w_codereg: 5e-4 # larger would cause the pose more stable, but smaller would lead to more variance on the shape (5e-4)
  converge:
    max_iter: 50    # max iteration number 
    epsilon_g: 1e-4 # convergence tolerance for gradient
    epsilon_c: 1e-2 # convergence tolerance for shape latent code' change rate
    epsilon_t: 1e-3 # convergence tolerance for pose parameters (translation, m)
    epsilon_r: 1e-0 # convergence tolerance for pose parameters (rotation, degree)
    epsilon_s: 1e-3 # convergence tolerance for pose parameters (scale, %)
  robust_iter: 2 # begin to use the robust loss from this iteration
  outlier:
    scale_max: 1.25
    scale_min: 0.5
    rot_max_deg: 60

vis:
  wandb_log_on: true
  vis_on: true
  vis_pause_s: 0.1
  object_radius_max_m: 0.08
  mc_res_mm: 4.0
  render_view: true
  rot_img: true # for 720 * 1280 images
  show_pix_sample: false

  